{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read all required files (ffilel price + ffiled macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carbon dir\n",
    "path_HBEA = \"../../02_Data_Processed/01_Carbon_Markets/01_Regional/HBEA_forward_filled.parquet\"\n",
    "path_GDEA = \"../../02_Data_Processed/01_Carbon_Markets/01_Regional/GDEA_forward_filled.parquet\"\n",
    "\n",
    "macro_dir_hubei = \"../../02_Data_Processed/02_Macroeconomic_Indicators/03_Forward_Filled_Daily/hubei/\"\n",
    "macro_dir_guangdong = \"../../02_Data_Processed/02_Macroeconomic_Indicators/03_Forward_Filled_Daily/guangdong/\"\n",
    "macro_dir_national_global = \"../../02_Data_Processed/02_Macroeconomic_Indicators/03_Forward_Filled_Daily/national_or_global/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_paths_hubei = glob.glob(os.path.join(macro_dir_hubei, \"*.parquet\"))\n",
    "macro_paths_guangdong = glob.glob(os.path.join(macro_dir_guangdong, \"*.parquet\"))\n",
    "macro_paths_national_global = glob.glob(os.path.join(macro_dir_national_global, \"*.parquet\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hbea = pd.read_parquet(path_HBEA)\n",
    "gdea = pd.read_parquet(path_GDEA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_frequency(df: pd.DataFrame):\n",
    "    if 'date' in df.columns:\n",
    "        df = df.set_index('date')\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "\n",
    "    # Find where the value changes (i.e., not forward-filled)\n",
    "    changes = df['value'].ne(df['value'].shift())\n",
    "    change_dates = df.index[changes]\n",
    "    # Calculate gaps\n",
    "    gaps = (change_dates[1:] - change_dates[:-1]).days\n",
    "    median_gap = np.median(gaps)\n",
    "    if median_gap <= 1.5:\n",
    "        return 'D'\n",
    "    elif 25 < median_gap < 35:\n",
    "        return 'M'\n",
    "    elif 80 < median_gap < 100:\n",
    "        return 'Q'\n",
    "    else:\n",
    "        return f'unknown (median gap: {median_gap})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_groups = {\n",
    "    \"hubei\": macro_paths_hubei,\n",
    "    \"guangdong\": macro_paths_guangdong,\n",
    "    \"national_global\": macro_paths_national_global,\n",
    "}\n",
    "\n",
    "dfs_by_group = {}\n",
    "\n",
    "for group_name, file_list in macro_groups.items():\n",
    "    group_dfs = {}\n",
    "    for path in file_list:\n",
    "        name = os.path.splitext(os.path.basename(path))[0]\n",
    "        df = pd.read_parquet(path)\n",
    "        df = df.set_index('date')\n",
    "        group_dfs[name] = df\n",
    "    dfs_by_group[group_name] = group_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shift either 1 day (daily) or 15 day (monthely, quarterly) based on frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_map = {'D': 1, 'M': 15, 'Q': 15}\n",
    "\n",
    "shifted_dfs_by_group = {}\n",
    "\n",
    "for group, group_dfs in dfs_by_group.items():\n",
    "    shifted_group = {}\n",
    "    for name, df in group_dfs.items():\n",
    "        freq = detect_frequency(df) \n",
    "        shift_n = shift_map.get(freq, 1)\n",
    "        name_shifted = f\"{name}_{shift_n}\"\n",
    "        # Fix: Use periods parameter for shift operation\n",
    "        shifted_group[name_shifted] = df.shift(periods=shift_n)\n",
    "    shifted_dfs_by_group[group] = shifted_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in shifted_dfs_by_group.keys():\n",
    "    for k in shifted_dfs_by_group[key].keys():\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_macro_for_join_index(df, new_col_name):\n",
    "    if 'date' in df.columns:\n",
    "        df = df.set_index('date')\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df.index.name = 'date'\n",
    "    return df[['value']].rename(columns={'value': new_col_name})\n",
    "\n",
    "def join_macros_on_index(main_df, macro_groups, group_keys):\n",
    "    result = main_df.copy()\n",
    "    if 'date' in result.columns:\n",
    "        result = result.set_index('date')\n",
    "    result.index = pd.to_datetime(result.index)\n",
    "    result.index.name = 'date'\n",
    "    \n",
    "    # Track column names to avoid duplicates\n",
    "    existing_cols = set(result.columns)\n",
    "    \n",
    "    for group in group_keys:\n",
    "        for col_name, macro_df in macro_groups[group].items():\n",
    "            # Skip if column already exists\n",
    "            if col_name in existing_cols:\n",
    "                print(f\"Skipping duplicate column: {col_name}\")\n",
    "                continue\n",
    "                \n",
    "            macro_ready = prep_macro_for_join_index(macro_df, col_name)\n",
    "            result = result.join(macro_ready, how='left')\n",
    "            existing_cols.add(col_name)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>vwap</th>\n",
       "      <th>volume_tons</th>\n",
       "      <th>turnover_cny</th>\n",
       "      <th>cum_turnover_cny</th>\n",
       "      <th>is_open</th>\n",
       "      <th>is_quiet</th>\n",
       "      <th>has_trade</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-04-28</th>\n",
       "      <td>24.43</td>\n",
       "      <td>24.49</td>\n",
       "      <td>57357.0</td>\n",
       "      <td>1404897.41</td>\n",
       "      <td>2051655.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-29</th>\n",
       "      <td>24.41</td>\n",
       "      <td>24.25</td>\n",
       "      <td>62994.0</td>\n",
       "      <td>1527794.05</td>\n",
       "      <td>2114649.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-30</th>\n",
       "      <td>24.38</td>\n",
       "      <td>24.36</td>\n",
       "      <td>83552.0</td>\n",
       "      <td>2034943.25</td>\n",
       "      <td>2198201.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-05-01</th>\n",
       "      <td>24.38</td>\n",
       "      <td>24.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2198201.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-05-02</th>\n",
       "      <td>24.38</td>\n",
       "      <td>24.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2198201.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-02</th>\n",
       "      <td>41.00</td>\n",
       "      <td>41.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>101215329.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-03</th>\n",
       "      <td>41.00</td>\n",
       "      <td>41.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>101215329.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-04</th>\n",
       "      <td>41.00</td>\n",
       "      <td>41.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>101215329.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-05</th>\n",
       "      <td>41.00</td>\n",
       "      <td>41.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>101215329.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-06</th>\n",
       "      <td>40.96</td>\n",
       "      <td>40.96</td>\n",
       "      <td>300.0</td>\n",
       "      <td>12288.00</td>\n",
       "      <td>101215629.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4027 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            close   vwap  volume_tons  turnover_cny  cum_turnover_cny  \\\n",
       "date                                                                    \n",
       "2014-04-28  24.43  24.49      57357.0    1404897.41         2051655.0   \n",
       "2014-04-29  24.41  24.25      62994.0    1527794.05         2114649.0   \n",
       "2014-04-30  24.38  24.36      83552.0    2034943.25         2198201.0   \n",
       "2014-05-01  24.38  24.36          0.0          0.00         2198201.0   \n",
       "2014-05-02  24.38  24.36          0.0          0.00         2198201.0   \n",
       "...           ...    ...          ...           ...               ...   \n",
       "2025-05-02  41.00  41.00          0.0          0.00       101215329.0   \n",
       "2025-05-03  41.00  41.00          0.0          0.00       101215329.0   \n",
       "2025-05-04  41.00  41.00          0.0          0.00       101215329.0   \n",
       "2025-05-05  41.00  41.00          0.0          0.00       101215329.0   \n",
       "2025-05-06  40.96  40.96        300.0      12288.00       101215629.0   \n",
       "\n",
       "            is_open  is_quiet  has_trade  \n",
       "date                                      \n",
       "2014-04-28     True     False       True  \n",
       "2014-04-29     True     False       True  \n",
       "2014-04-30     True     False       True  \n",
       "2014-05-01    False     False      False  \n",
       "2014-05-02    False     False      False  \n",
       "...             ...       ...        ...  \n",
       "2025-05-02    False     False      False  \n",
       "2025-05-03    False     False      False  \n",
       "2025-05-04    False     False      False  \n",
       "2025-05-05    False     False      False  \n",
       "2025-05-06     True     False       True  \n",
       "\n",
       "[4027 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hbea_final = join_macros_on_index(hbea, shifted_dfs_by_group, ['hubei', 'national_global'])\n",
    "gdea_final = join_macros_on_index(gdea, shifted_dfs_by_group, ['guangdong', 'national_global'])\n",
    "hbea_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save final datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory created: ../../02_Data_Processed/03_Feature_Engineered/\n"
     ]
    }
   ],
   "source": [
    "# Create output directory\n",
    "output_dir = \"../../02_Data_Processed/03_Feature_Engineered/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(f\"Output directory created: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved HBEA data: (4027, 8)\n",
      "Saved GDEA data: (3967, 8)\n"
     ]
    }
   ],
   "source": [
    "# Save the joined datasets\n",
    "hbea_final.to_parquet(os.path.join(output_dir, \"HBEA_daily_with_macro.parquet\"))\n",
    "gdea_final.to_parquet(os.path.join(output_dir, \"GDEA_daily_with_macro.parquet\"))\n",
    "\n",
    "# Also save as CSV for easy inspection\n",
    "hbea_final.to_csv(os.path.join(output_dir, \"HBEA_daily_with_macro.csv\"))\n",
    "gdea_final.to_csv(os.path.join(output_dir, \"GDEA_daily_with_macro.csv\"))\n",
    "\n",
    "print(f\"Saved HBEA data: {hbea_final.shape}\")\n",
    "print(f\"Saved GDEA data: {gdea_final.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in HBEA:\n",
      "0\n",
      "\n",
      "Missing values in GDEA:\n",
      "0\n",
      "\n",
      "HBEA Date Range: 2014-04-28 00:00:00 to 2025-05-06 00:00:00\n",
      "GDEA Date Range: 2014-06-27 00:00:00 to 2025-05-06 00:00:00\n",
      "\n",
      "Total columns in final dataset: 8\n",
      "Carbon columns: ['is_open']\n",
      "Number of macro columns: 7\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values in HBEA:\")\n",
    "print(hbea_final.isnull().sum().sum())\n",
    "print(\"\\nMissing values in GDEA:\")\n",
    "print(gdea_final.isnull().sum().sum())\n",
    "\n",
    "# Date range verification\n",
    "print(f\"\\nHBEA Date Range: {hbea_final.index.min()} to {hbea_final.index.max()}\")\n",
    "print(f\"GDEA Date Range: {gdea_final.index.min()} to {gdea_final.index.max()}\")\n",
    "\n",
    "# Column summary\n",
    "print(f\"\\nTotal columns in final dataset: {len(hbea_final.columns)}\")\n",
    "carbon_cols = [col for col in hbea_final.columns if col in ['close_price', 'volume', 'is_open']]\n",
    "macro_cols = [col for col in hbea_final.columns if col not in ['close_price', 'volume', 'is_open']]\n",
    "print(f\"Carbon columns: {carbon_cols}\")\n",
    "print(f\"Number of macro columns: {len(macro_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary statistics saved.\n",
      "\n",
      "First few rows of summary statistics:\n",
      "                     HBEA_mean      HBEA_std     GDEA_mean      GDEA_std\n",
      "close             3.070421e+01  1.111606e+01  3.591004e+01  2.308819e+01\n",
      "vwap              3.052707e+01  1.106463e+01  3.535630e+01  2.333603e+01\n",
      "volume_tons       2.464408e+04  6.285936e+04  5.238661e+04  1.629808e+05\n",
      "turnover_cny      6.822986e+05  1.852792e+06  1.446148e+06  4.158838e+06\n",
      "cum_turnover_cny  5.641410e+07  2.837768e+07  2.358405e+09  2.030044e+09\n"
     ]
    }
   ],
   "source": [
    "# Generate summary statistics for numeric columns\n",
    "numeric_cols_hbea = hbea_final.select_dtypes(include=[np.number]).columns\n",
    "numeric_cols_gdea = gdea_final.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Create summary statistics DataFrame\n",
    "summary_stats = pd.DataFrame({\n",
    "    'HBEA_mean': hbea_final[numeric_cols_hbea].mean(),\n",
    "    'HBEA_std': hbea_final[numeric_cols_hbea].std(),\n",
    "    'GDEA_mean': gdea_final[numeric_cols_gdea].mean(),\n",
    "    'GDEA_std': gdea_final[numeric_cols_gdea].std()\n",
    "})\n",
    "\n",
    "# Save summary statistics\n",
    "summary_stats.to_csv(os.path.join(output_dir, \"summary_statistics.csv\"))\n",
    "print(\"Summary statistics saved.\")\n",
    "print(\"\\nFirst few rows of summary statistics:\")\n",
    "print(summary_stats.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Description\n",
    "\n",
    "This notebook creates two main datasets with carbon prices joined with lagged macroeconomic indicators:\n",
    "\n",
    "### Output Files:\n",
    "- `HBEA_daily_with_macro.parquet/csv` - Hubei carbon prices with macro features\n",
    "- `GDEA_daily_with_macro.parquet/csv` - Guangdong carbon prices with macro features\n",
    "- `summary_statistics.csv` - Summary statistics for all numeric columns\n",
    "\n",
    "### Dataset Structure:\n",
    "Each dataset contains:\n",
    "- **Index**: `date` (daily frequency, includes both trading and non-trading days)\n",
    "- **Carbon columns**: \n",
    "  - `close_price` - Daily closing price\n",
    "  - `volume` - Trading volume\n",
    "  - `is_open` - Whether the market was open (1) or closed (0)\n",
    "- **Macro columns**: All indicators with appropriate lags applied\n",
    "  - Format: `[indicator_name]_[lag_days]`\n",
    "  - Example: `China_CPI_YoY_ffill_daily_15` (15-day lag for monthly data)\n",
    "  - Example: `CFETS_SpotFX_USD_CNY_ffill_daily_1` (1-day lag for daily data)\n",
    "\n",
    "### Lag Structure:\n",
    "The lag structure ensures no look-ahead bias in trading strategies:\n",
    "- **Daily indicators**: 1-day lag (e.g., FX rates, energy futures)\n",
    "- **Monthly/Quarterly indicators**: 15-day lag (e.g., CPI, Industrial Value Added, GDP)\n",
    "\n",
    "This means that on any given trading day, you only have access to information that would have been publicly available by that date."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carbon-trading",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
